{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c6d58-fb12-4af4-bebf-551e24f70823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e54e7c1b-39ad-4f4e-96aa-be3df47b935c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    from paper:\n",
    "        After analysing the data, we find a relationship between the target variable with other features and\n",
    "        selected two features: number of rooms (average number\n",
    "        of rooms per dwelling) and LSTAT (percentage of lower\n",
    "        status of the population). We built a machine learning\n",
    "        model for determining the prices of Boston houses based\n",
    "        on two features we selected.\n",
    "        \n",
    "        Next, we split the dataset\n",
    "        into training and test samples, 80% and 20%, respectively.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19910c-276d-4280-91e0-f2ff474b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0212840-76c2-4608-ae4e-2e11d8b440ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import functools\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f2f7e78-dfa2-4da3-b330-db2a7e6989b0",
   "metadata": {},
   "source": [
    "import random\n",
    "# Set random seeds\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b0f9b-4647-4b42-a6bf-f76a65619c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "total_sample = 506\n",
    "train_sample = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4c981-bfab-4509-bf13-7fb0dc54095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_heatmap(_model, x1_num=100, x2_num=100, name='model'):\n",
    "    pred = []\n",
    "    for i in range(x1_num):\n",
    "        temp_history = []\n",
    "        for j in range(x2_num):\n",
    "            if name == 'Hybrid MLP':\n",
    "                x1 = np.pi /2 * i/x1_num\n",
    "                x2 = np.pi /2 * j/x2_num\n",
    "            else:\n",
    "                x1 = i/x1_num * 5 + 4\n",
    "                x2 = j/x2_num  * 40\n",
    "            y_pred = _model(torch.tensor([x1, x2], dtype=torch.float32))\n",
    "\n",
    "            prediction = y_pred.detach().item()\n",
    "\n",
    "            temp_history.append(prediction)\n",
    "        pred.append(temp_history)\n",
    "\n",
    "    # make the plot more intuitive\n",
    "    # horizon direction: LSTAT\n",
    "    # vertical direction: number of room\n",
    "    pred = list(reversed(pred))\n",
    "    \n",
    "\n",
    "    \n",
    "    # return heatmap\n",
    "    return pred\n",
    "\n",
    "def display_heatmap(pred, name='model'):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.xlabel('LSTAT')\n",
    "    plt.ylabel('# room')\n",
    "    plt.title(name)\n",
    "    # plt.title(name).set_color(\"white\")\n",
    "\n",
    "    im = plt.imshow(pred, vmin=5, vmax=45, cmap=plt.cm.get_cmap('ocean'))\n",
    "    # im = plt.imshow(pred, vmin=11, vmax=49, cmap=plt.cm.get_cmap('ocean'))\n",
    "    \n",
    "    plt.rcParams['axes.grid'] = False\n",
    "    # this stop the warning\n",
    "    \n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    plt.title(name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d7692-c0b1-4789-bc5b-c0b1b329a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_eval = torch.nn.L1Loss()\n",
    "\n",
    "# use L1 loss\n",
    "def eval_model(_model, _data_loader=None, epoch_num=-1, scale=1., history_list=None, store_history=True):\n",
    "    _loss = 0\n",
    "    for xs, ys in _data_loader:\n",
    "        pred = _model(xs * scale)\n",
    "        _loss += loss_eval(pred, ys).detach()\n",
    "        \n",
    "    avg_loss = _loss\n",
    "    if store_history:\n",
    "        history_list.append(avg_loss)\n",
    "    return history_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b1ed1-e75c-4d81-b5fc-4b30f3fc30b8",
   "metadata": {},
   "source": [
    "Multi layer perceptron\n",
    "======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d25879-9963-42be-a8ef-9d4f1c420a06",
   "metadata": {},
   "source": [
    "![title](img/regression_mlp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd527c40-03c4-4e27-ad2c-1bf6940ee62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp():\n",
    "    with warnings.catch_warnings(): \n",
    "    # You should probably not use this dataset.\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        X, y = load_boston(return_X_y=True)\n",
    "        \n",
    "        # to tensor, and only select # numnber of rooms and LSTAT as input X\n",
    "        X = torch.tensor(X[:, [5, 12]]).float()\n",
    "        y = np.float32(y.reshape((total_sample, 1)))\n",
    "    \n",
    "    eval_loss_history = []\n",
    "    # sequential model\n",
    "    fc_1 = torch.nn.Linear(2, 4)\n",
    "    fc_2 = torch.nn.Linear(4, 16)\n",
    "    fc_3 = torch.nn.Linear(16, 1)\n",
    "    relu = torch.nn.ReLU()\n",
    "    layers = [fc_1, relu, fc_2, relu, fc_3]\n",
    "    model = torch.nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        list(zip(X, y))[:train_sample], batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        list(zip(X, y))[train_sample:], batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    # model & traning\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        _loss = 0\n",
    "\n",
    "        for xs, ys in data_loader:\n",
    "            # print(xs.dtype)\n",
    "            # print(ys.dtype)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_evaluated = loss(model(xs), ys)\n",
    "            loss_evaluated.backward()\n",
    "            _loss += loss_evaluated\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "        # accuracy = test(model, X[train_sample:], y[train_sample:], logits=True)\n",
    "        # acc.append(accuracy)\n",
    "\n",
    "        eval_loss_history = eval_model(model, _data_loader=test_loader, epoch_num=epoch, history_list=eval_loss_history)\n",
    "    return [eval_loss_history, gen_heatmap(model, name='MLP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4db4b0-8832-4f54-bb99-5fcabe384456",
   "metadata": {},
   "source": [
    "### Hybrid Multi layer perceptron\n",
    "======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f719d17-1d7c-403d-a78c-ce3290ce90b8",
   "metadata": {},
   "source": [
    "![title](img/regression_hmlp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6227c4-9f44-48f7-99d9-e74032d039f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_hybrid():\n",
    "    h_eval_loss_history = []\n",
    "    n_qubits = 4\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\")\n",
    "    def qnode(inputs, weights):\n",
    "        qml.RX(inputs[0], wires=0)\n",
    "        qml.RX(inputs[1], wires=2)\n",
    "\n",
    "        qml.CNOT(wires=[0, 1])\n",
    "        qml.CNOT(wires=[1, 2])\n",
    "        qml.CNOT(wires=[2, 3])\n",
    "        qml.CNOT(wires=[3, 0])\n",
    "\n",
    "        qml.RY(weights[0, 0], wires=0)\n",
    "        qml.RY(weights[0, 1], wires=1)\n",
    "        qml.RY(weights[0, 2], wires=2)\n",
    "        qml.RY(weights[0, 3], wires=3)\n",
    "\n",
    "        qml.CNOT(wires=[0, 1])\n",
    "        qml.CNOT(wires=[1, 2])\n",
    "        qml.CNOT(wires=[2, 3])\n",
    "        qml.CNOT(wires=[3, 0])\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(wires=0)), \n",
    "                qml.expval(qml.PauliZ(wires=1)),\n",
    "                qml.expval(qml.PauliZ(wires=2)),\n",
    "                qml.expval(qml.PauliZ(wires=3))]\n",
    "\n",
    "\n",
    "    # hybrid circuits, sequential model\n",
    "    fc_test = torch.nn.Linear(4, 40, bias=False)\n",
    "    # fc_1 = torch.nn.Linear(4, 4, bias=False)\n",
    "    fc_2 = torch.nn.Linear(40, 1)\n",
    "    relu = torch.nn.ReLU()\n",
    "    torch.nn.init.uniform_(fc_2.weight, a=-50, b=50)\n",
    "\n",
    "    # pennylane cirtuit convertion, to pytorch layer\n",
    "    n_layers = 1\n",
    "    weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "    qlayer = qml.qnn.TorchLayer(qnode, weight_shapes, init_method={'weights': functools.partial(torch.nn.init.uniform_, b=np.pi*0.6)})\n",
    "\n",
    "    # h_layers = [qlayer, fc_1, relu, fc_2]\n",
    "    h_layers = OrderedDict(([\n",
    "                ('qlayer', qlayer),\n",
    "                ('fc_test', fc_test),\n",
    "                ('relu', relu),\n",
    "                # ('fc_1', fc_1), \n",
    "                # ('relu', relu), \n",
    "                ('fc_2', fc_2)]))\n",
    "    h_model = torch.nn.Sequential(h_layers)\n",
    "\n",
    "    opt = torch.optim.Adam(h_model.parameters(), lr=0.003)\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    # handle input different comparing with MLP, use input as radian\n",
    "\n",
    "    def NormalizeData(data):\n",
    "        data = np.transpose(data)\n",
    "        data[0] = (data[0] - np.min(data[0])) / (np.max(data[0]) - np.min(data[0]))\n",
    "        data[1] = (data[1] - np.min(data[1])) / (np.max(data[1]) - np.min(data[1]))\n",
    "        return np.transpose(data)\n",
    "\n",
    "    def StandardizeData(data):\n",
    "        data = np.transpose(data)\n",
    "        mean = [np.mean(data[0]), np.mean(data[1])]\n",
    "        std = [np.std(data[0]), np.std(data[1])]\n",
    "        data[0] = (data[0] - mean[0]) - std[0]\n",
    "        data[1] = (data[1] - mean[1]) - std[1]\n",
    "        return np.transpose(data)\n",
    "\n",
    "    def MinMaxScaler(data):\n",
    "        data = np.transpose(data)\n",
    "        std = [np.std(data[0]), np.std(data[1])]\n",
    "        data[0] = std[0] * (np.max(data[0]) - np.min(data[0])) + np.min(data[0])\n",
    "        data[1] = std[1] * (np.max(data[1]) - np.min(data[1])) + np.min(data[1])\n",
    "        return np.transpose(data)\n",
    "\n",
    "    def robustScaler(data):\n",
    "        data = np.transpose(data)\n",
    "        q1 = [np.quantile(data[0], 0.25), np.quantile(data[1], 0.25)]\n",
    "        q3 = [np.quantile(data[0], 0.25), np.quantile(data[1], 0.75)]\n",
    "        data[0] = (data[0]-q1[0])/(q3[0] - q1[0])\n",
    "        data[1] = (data[1]-q1[1])/(q3[1] - q1[1])\n",
    "        return np.transpose(data)\n",
    "\n",
    "    def hybrid_dataloader():\n",
    "        with warnings.catch_warnings(): \n",
    "            # You should probably not use this dataset.\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            X, y = load_boston(return_X_y=True)\n",
    "            # # to tensor, and only select # numnber of rooms and LSTAT as input X\n",
    "            X = X[:, [5, 12]]\n",
    "            X = NormalizeData(X)\n",
    "            # y = NormalizeData(y)\n",
    "            # plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "            X = torch.tensor(X).float()\n",
    "            # print(y.dtype)\n",
    "            y = torch.tensor(y.reshape((total_sample, 1))).float()\n",
    "            # print(y.dtype)\n",
    "\n",
    "            return [torch.utils.data.DataLoader(\n",
    "            list(zip(X, y))[:train_sample], batch_size=batch_size, shuffle=True, drop_last=True\n",
    "            ),\n",
    "                   torch.utils.data.DataLoader(\n",
    "            list(zip(X, y))[train_sample:], batch_size=batch_size, shuffle=True, drop_last=True\n",
    "            )]\n",
    "\n",
    "    # model & traning\n",
    "\n",
    "    flag = True\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        _loss = 0\n",
    "\n",
    "        for xs, ys in hybrid_dataloader()[0]:\n",
    "\n",
    "            xs *= np.pi/2\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_evaluated = loss(h_model(xs), ys)\n",
    "            loss_evaluated.backward()\n",
    "            _loss += loss_evaluated\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "        h_eval_loss_history = eval_model(h_model, _data_loader=hybrid_dataloader()[1], scale=np.pi/2, epoch_num=epoch, history_list=h_eval_loss_history)\n",
    "    return [h_eval_loss_history, gen_heatmap(h_model, name='Hybrid MLP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d06421-23ad-42bd-b399-370084a9b8bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comparision\n",
    "======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d870e8-692a-401e-b1de-52a97e875f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883c6d7-9a17-44c0-adfd-9336ae876b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_loss = 0\n",
    "mlp_heatmap = 0\n",
    "hmlp_loss = 0\n",
    "hmlp_heatmap = 0\n",
    "\n",
    "# size: [runs, 2, epoch, 100, 100]\n",
    "for i in range(runs):\n",
    "    result_mlp = train_mlp()\n",
    "    result_hybrid = train_hybrid()\n",
    "    \n",
    "    mlp_loss += np.asarray(result_mlp[0])\n",
    "    mlp_heatmap += np.asarray(result_mlp[1])\n",
    "    hmlp_loss += np.asarray(result_hybrid[0])\n",
    "    hmlp_heatmap += np.asarray(result_hybrid[1])\n",
    "\n",
    "mlp_loss /= runs\n",
    "mlp_heatmap /= runs\n",
    "hmlp_loss /= runs\n",
    "hmlp_heatmap /= runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d4700-4c51-4b87-8ed4-eed48223645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot benchmark comparing between mlp and hmlp\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch #\")\n",
    "\n",
    "ax.plot(mlp_loss, '.-', label=\"MLP loss\")\n",
    "ax.plot(hmlp_loss, '.-', label=\"H_MLP loss\")\n",
    "# ax.plot(*, '.-', label=\"Backprop\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch #\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "display_heatmap(mlp_heatmap, name='MLP')\n",
    "display_heatmap(hmlp_heatmap, name='Hybrid MLP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
